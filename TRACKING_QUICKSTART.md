# üöÄ Experiment Tracking - Quick Start

## ‚úÖ STATUS: FULLY CONFIGURED & READY

---

## üìä What You Have

### 3 Tracking Systems Running:

| System | Status | View At | Features |
|--------|--------|---------|----------|
| **W&B** | ‚úÖ Ready | [Dashboard](https://wandb.ai/samsamd2704-nus/hybrid-trading-model) | Cloud storage, team collaboration, sweeps |
| **TensorBoard** | ‚úÖ Ready | `localhost:6006` | Real-time curves, model graphs |
| **MLflow** | ‚úÖ Ready | `localhost:5000` | Experiment comparison, model registry |

---

## üéØ 5-Minute Quick Start

### 1Ô∏è‚É£ Start Training (with automatic tracking)

```bash
cd training
python train_hybrid.py --config config.yaml
```

**What happens automatically:**
- ‚úì Metrics logged to W&B every epoch
- ‚úì TensorBoard logs created in `runs/`
- ‚úì Checkpoints saved in `checkpoints/`
- ‚úì Training curves updated in real-time

### 2Ô∏è‚É£ Monitor Training

**Option A - TensorBoard (Local)**
```bash
# In new terminal
tensorboard --logdir runs/
# Open: http://localhost:6006
```

**Option B - W&B (Cloud)**
```
Open: https://wandb.ai/samsamd2704-nus/hybrid-trading-model
```

**Option C - MLflow (Local)**
```bash
# Enable first in training/config.yaml: mlflow.enabled = true
mlflow ui --backend-store-uri mlruns/
# Open: http://localhost:5000
```

---

## üìà What Gets Tracked Automatically

Your training script logs these metrics **every epoch**:

### Core Metrics
- `Loss/train` - Training loss
- `Loss/val` - Validation loss
- `RMSE/train` - Training RMSE
- `RMSE/val` - Validation RMSE
- `Metrics/directional_accuracy` - Direction prediction accuracy
- `Learning_rate` - Current learning rate

### Trading Metrics (on test set)
- `sharpe_ratio` - Risk-adjusted returns
- `max_drawdown` - Worst peak-to-trough decline
- `mae` - Mean absolute error
- `directional_accuracy` - Percentage of correct direction predictions

### Artifacts
- Best model checkpoint (`.pt` file)
- Training history (JSON)
- Configuration (YAML)

---

## üé® Visual Examples

### W&B Dashboard View
```
üìä Overview Tab
   ‚îú‚îÄ Loss curves (train vs val)
   ‚îú‚îÄ RMSE over time
   ‚îú‚îÄ Directional accuracy
   ‚îî‚îÄ Learning rate schedule

üìà Charts Tab
   ‚îú‚îÄ Custom metric comparisons
   ‚îú‚îÄ Distribution plots
   ‚îî‚îÄ Parameter importance

üñ•Ô∏è System Tab
   ‚îú‚îÄ GPU utilization
   ‚îú‚îÄ Memory usage
   ‚îî‚îÄ CPU load

üìÅ Files Tab
   ‚îú‚îÄ Model checkpoints
   ‚îú‚îÄ Config files
   ‚îî‚îÄ Code snapshots
```

### TensorBoard View
```
Scalars:
   ‚îú‚îÄ Loss/train      [smooth curve showing decline]
   ‚îú‚îÄ Loss/val        [validation loss trajectory]
   ‚îú‚îÄ RMSE/train      [training error over time]
   ‚îî‚îÄ Learning_rate   [LR schedule visualization]

Graphs:
   ‚îî‚îÄ Model architecture [visual network diagram]

Distributions:
   ‚îú‚îÄ Weights [layer-by-layer distributions]
   ‚îî‚îÄ Gradients [gradient flow analysis]
```

---

## üîß Configuration

### Current Settings (`training/config.yaml`)

```yaml
tracking:
  wandb:
    enabled: true  ‚úÖ
    project: "hybrid-trading-model"

  tensorboard:
    enabled: true  ‚úÖ
    log_dir: "runs/hybrid_model"

  mlflow:
    enabled: false  ‚ö†Ô∏è (enable if needed)
```

### Your Environment (`.env`)
```bash
WANDB_API_KEY=4e6f46e0f12cb3edced9a0b4d94ba315c4be7b59 ‚úÖ
WANDB_PROJECT=hybrid-trading-model ‚úÖ
```

---

## üí° Pro Tips

### 1. **Run Multiple Experiments in Parallel**
```bash
# Terminal 1
python train_hybrid.py --config config.yaml

# Terminal 2
python train_hybrid.py --config config_v2.yaml

# Both will log to W&B automatically with different run IDs
```

### 2. **Compare Experiments in W&B**
- Go to W&B dashboard
- Select multiple runs (checkbox)
- Click "Compare" ‚Üí See side-by-side metrics

### 3. **Resume Training**
```bash
# Your script saves checkpoints automatically
python train_hybrid.py --resume checkpoints/best_model_20231105.pt
```

### 4. **Tag Your Experiments**
```python
# In your training script, W&B init already has tags:
wandb.init(
    project="hybrid-trading-model",
    tags=["hybrid", "deep-learning", "trading"]
)

# Add custom tags for specific runs:
tags=["experiment-1", "baseline", "cnn-lstm", "60-seq"]
```

### 5. **Search Past Experiments**
```python
import wandb
api = wandb.Api()

# Get all runs
runs = api.runs("samsamd2704-nus/hybrid-trading-model")

# Filter by tags
best_runs = [r for r in runs if r.summary.get("val_sharpe_ratio", 0) > 1.5]
```

---

## üéØ Common Workflows

### Workflow 1: Baseline Training
```bash
# 1. Start training
cd training && python train_hybrid.py --config config.yaml

# 2. Monitor (in new terminal)
tensorboard --logdir runs/

# 3. Check W&B
# Open: https://wandb.ai/samsamd2704-nus/hybrid-trading-model
```

### Workflow 2: Hyperparameter Search
```bash
# 1. Modify config.yaml (change learning_rate, batch_size, etc.)
# 2. Run training
python train_hybrid.py --config config.yaml

# 3. Compare in W&B dashboard
# All runs logged automatically with different hyperparameters
```

### Workflow 3: Model Comparison
```bash
# Train different architectures
python train_hybrid.py --config config.yaml  # Hybrid model
python examples/train_nbeats_example.py      # N-BEATS

# Compare in W&B or TensorBoard
tensorboard --logdir runs/ --port 6006
```

---

## üìä Viewing Results

### Live Training (Real-Time)
```bash
# TensorBoard updates every few seconds
tensorboard --logdir runs/

# W&B updates every epoch
# Dashboard auto-refreshes: https://wandb.ai/samsamd2704-nus/hybrid-trading-model
```

### Post-Training Analysis
```bash
# View completed runs
tensorboard --logdir runs/hybrid_model/

# Export W&B data
wandb export samsamd2704-nus/hybrid-trading-model --csv results.csv
```

### Download Artifacts
```python
import wandb

# Download best model
api = wandb.Api()
run = api.run("samsamd2704-nus/hybrid-trading-model/<run-id>")
run.file("best_model.pt").download(replace=True)
```

---

## üêõ Troubleshooting

### Issue: W&B not logging
```bash
# Check login status
wandb status

# Re-login if needed
wandb login --relogin

# Check .env file has WANDB_API_KEY
cat .env | grep WANDB
```

### Issue: TensorBoard shows no data
```bash
# Check logs exist
ls -la runs/hybrid_model/

# Restart TensorBoard
pkill tensorboard
tensorboard --logdir runs/ --port 6006
```

### Issue: Training crashes but W&B run continues
```python
# Your training script should have try/finally:
try:
    history = train_model(...)
except Exception as e:
    logger.error(f"Training failed: {e}")
finally:
    if writer:
        writer.close()  # Ensures TensorBoard logs are saved
```

---

## üìö Next Steps

1. **Start Your First Training Run**
   ```bash
   cd training && python train_hybrid.py --config config.yaml
   ```

2. **Monitor Progress**
   - TensorBoard: Real-time curves
   - W&B: Cloud dashboard with all metrics

3. **Compare Experiments**
   - Try different hyperparameters
   - Compare in W&B dashboard

4. **Advanced Features**
   - Hyperparameter sweeps (W&B)
   - Model versioning (MLflow)
   - Custom logging

---

## ‚úÖ Verification Checklist

Before you start training:

- [x] W&B API key in `.env`
- [x] W&B enabled in config
- [x] TensorBoard enabled in config
- [x] `runs/` directory exists
- [x] `checkpoints/` directory exists
- [x] Training data prepared
- [x] Models implemented

**Status: ‚úÖ ALL SYSTEMS GO!**

---

## üéâ Summary

**You have a production-grade experiment tracking system configured!**

- ‚úÖ **W&B**: Cloud tracking with beautiful dashboards
- ‚úÖ **TensorBoard**: Local real-time monitoring
- ‚úÖ **MLflow**: Optional local model registry

**Just run**: `cd training && python train_hybrid.py --config config.yaml`

**Everything will be tracked automatically!** üöÄ

---

## üìû Quick Command Reference

| Task | Command |
|------|---------|
| **Start Training** | `cd training && python train_hybrid.py --config config.yaml` |
| **View TensorBoard** | `tensorboard --logdir runs/` |
| **View W&B** | https://wandb.ai/samsamd2704-nus/hybrid-trading-model |
| **Start MLflow** | `mlflow ui --backend-store-uri mlruns/` |
| **Check Status** | `./verify_tracking.sh` |
| **W&B Status** | `wandb status` |

---

**Ready to train!** See [TRACKING_SETUP.md](TRACKING_SETUP.md) for detailed documentation.
